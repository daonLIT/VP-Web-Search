# app/agent_graph_guidance.py
# ìµœì¢… ê·¸ë˜í”„
from __future__ import annotations

from typing import Optional
import logging
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from langgraph.graph import StateGraph, END, MessagesState
from langgraph.prebuilt import ToolNode, tools_condition

from app.tools.agent_tools import build_tools

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


SYSTEM_PROMPT_GUIDANCE = """\
ë„ˆëŠ” ë‹¤ë¥¸ ì‹œìŠ¤í…œì˜ ìš”ì²­ì„ ë°›ì•„ ë³´ì´ìŠ¤í”¼ì‹± ìˆ˜ë²• ì§€ì¹¨ì„ ì œê³µí•˜ëŠ” ì—ì´ì „íŠ¸ë‹¤.

ì…ë ¥ í˜•ì‹:
{
  "phishing": true,
  "type": "ê²€ê²½ ì‚¬ì¹­",
  "scenario": "ê²€ì°° ì‚¬ì¹­í•´ì„œ í˜„ê¸ˆ í¸ì·¨",
  "victim_profile": {...}  // ì„ íƒ
}

ì ˆì°¨:
1) search_existing_guidance(phishing_type=type, scenario_hint=scenario)ë¥¼ í˜¸ì¶œí•´ DBì—ì„œ ê²€ìƒ‰
2) found=trueì´ê³  count>=1ì´ë©´:
   - guidances[0]ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
   - ì¶œë ¥ JSON í˜•ì‹:
   {
     "status": "found_in_db",
     "guidance": {...},
     "source": "database"
   }
3) found=falseì´ë©´:
   - generate_targeted_guidance(phishing_type=type, scenario=scenario, victim_profile=...)ë¥¼ í˜¸ì¶œ
   - store_guidance_to_db(guidance=ìƒì„±ê²°ê³¼)ë¥¼ í˜¸ì¶œí•´ ì €ì¥
   - ì¶œë ¥ JSON í˜•ì‹:
   {
     "status": "generated_new",
     "guidance": {...},
     "guidance_id": "...",
     "source": "web_search"
   }

ìµœì¢… ì¶œë ¥ì€ ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ì„±í•˜ë¼.
""".strip()


def build_guidance_agent_graph(vectordb, model_name: Optional[str] = None):
    """
    ì™¸ë¶€ ì‹œìŠ¤í…œ ìš”ì²­ ì²˜ë¦¬ìš© ì—ì´ì „íŠ¸ ê·¸ë˜í”„
    """
    all_tools = build_tools(vectordb)
    
    # í•„ìš”í•œ ë„êµ¬ë§Œ ì„ íƒ
    allow = {
        "search_existing_guidance",
        "generate_targeted_guidance", 
        "store_guidance_to_db"
    }
    tools = [t for t in all_tools if t.name in allow]
    
    if len(tools) < 3:
        raise RuntimeError(f"Missing tools. Found: {[t.name for t in tools]}")
    
    llm = ChatOpenAI(
        model=(model_name or "gpt-4o"),
        temperature=0,
        timeout=90,
        max_retries=3,
    ).bind_tools(tools)
    
    def agent_node(state: MessagesState):
        messages = [SystemMessage(content=SYSTEM_PROMPT_GUIDANCE)] + state["messages"]
        logger.info("ğŸ¤– Agent í˜¸ì¶œ ì¤‘...")
        resp = llm.invoke(messages)

        # ë„êµ¬ í˜¸ì¶œ ë¡œê¹…
        if hasattr(resp, 'tool_calls') and resp.tool_calls:
            for tc in resp.tool_calls:
                logger.info(f"ğŸ”§ ë„êµ¬ í˜¸ì¶œ: {tc.get('name', 'unknown')}")

        return {"messages": [resp]}
    
    def tools_node_wrapper(state: MessagesState):
        logger.info("âš™ï¸  ë„êµ¬ ì‹¤í–‰ ì¤‘...")
        tool_node = ToolNode(tools)
        result = tool_node.invoke(state)
        logger.info("âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ")
        return result
    
    graph = StateGraph(MessagesState)
    graph.add_node("agent", agent_node)
    graph.add_node("tools", tools_node_wrapper)
    
    graph.set_entry_point("agent")
    graph.add_conditional_edges("agent", tools_condition, {"tools": "tools", END: END})
    graph.add_edge("tools", "agent")
    
    return graph.compile()