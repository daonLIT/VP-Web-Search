# app/tools/agent_tools_attack.py (ìƒˆ íŒŒì¼)
from __future__ import annotations

import json
from typing import List, Dict, Any, Optional
from datetime import datetime, timezone

from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch


@tool("analyze_conversation_summary")
def analyze_conversation_summary(
    conversation_summary: str,
) -> Dict[str, Any]:
    """
    ëŒ€í™” ìš”ì•½ì„ ë¶„ì„í•˜ì—¬ í”¼í•´ì í”„ë¡œí•„ê³¼ ì·¨ì•½ì  ì§ˆë¬¸ì„ ìƒì„±í•œë‹¤.
    
    ì…ë ¥:
    - conversation_summary: ëŒ€í™” ìš”ì•½ í…ìŠ¤íŠ¸
    
    ì¶œë ¥:
    {
        "victim_profile": {
            "age_group": "30ëŒ€",
            "occupation": "ì§ì¥ì¸",
            "gender": "ë‚¨ì„±",
            "characteristics": [...]
        },
        "current_scenario": "ê²€ê²½ ì‚¬ì¹­",
        "victim_suspicion_points": [...],
        "vulnerability_questions": [
            "30ëŒ€ëŠ” ì–´ë–¤ ì ì´ ì·¨ì•½í• ê¹Œ?",
            "ì§ì¥ì¸ì€ ë¬´ì—‡ì— ì•½í• ê¹Œ?",
            ...
        ]
    }
    """
    llm = ChatOpenAI(model="gpt-4o", temperature=0.3, timeout=30)
    
    prompt = f"""
ë„ˆëŠ” ë³´ì´ìŠ¤í”¼ì‹± ëŒ€í™”ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ë‹¤.
ì•„ë˜ ëŒ€í™” ìš”ì•½ì„ ì½ê³ , ê³µê²©ì ê´€ì ì—ì„œ í”¼í•´ìì˜ ì·¨ì•½ì ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ë¼.

[ëŒ€í™” ìš”ì•½]
{conversation_summary}

ì¶œë ¥ í˜•ì‹ (JSONë§Œ):
{{
  "victim_profile": {{
    "age_group": "ì—°ë ¹ëŒ€ (ì˜ˆ: 20ëŒ€, 30ëŒ€, 60ëŒ€ ì´ìƒ)",
    "occupation": "ì§ì—… (ì˜ˆ: ì§ì¥ì¸, ëŒ€í•™ìƒ, ì£¼ë¶€, í‡´ì§ì)",
    "gender": "ì„±ë³„ (ë‚¨ì„±/ì—¬ì„±/ì•Œ ìˆ˜ ì—†ìŒ)",
    "characteristics": ["íŠ¹ì§•1", "íŠ¹ì§•2", "íŠ¹ì§•3"]
  }},
  "current_scenario": "í˜„ì¬ ì‚¬ìš©ëœ ì‹œë‚˜ë¦¬ì˜¤ (ì˜ˆ: ê²€ê²½ ì‚¬ì¹­, ê°€ì¡± ì‚¬ì¹­, ëŒ€ì¶œ ì‚¬ê¸°)",
  "victim_suspicion_points": [
    "í”¼í•´ìê°€ ì˜ì‹¬í•œ í¬ì¸íŠ¸ 1",
    "í”¼í•´ìê°€ ì˜ì‹¬í•œ í¬ì¸íŠ¸ 2",
    ...
  ],
  "vulnerability_questions": [
    "ì´ ì—°ë ¹ëŒ€ëŠ” ì–´ë–¤ ì ì´ ì·¨ì•½í• ê¹Œ?",
    "ì´ ì§ì—…êµ°ì€ ë¬´ì—‡ì— ì•½í• ê¹Œ?",
    "ì–´ë–¤ ë§íˆ¬/í‘œí˜„ì´ íš¨ê³¼ì ì¼ê¹Œ?",
    "ì–´ë–¤ ì‹¬ë¦¬ì  ì••ë°•ì´ í†µí• ê¹Œ?",
    ...
  ]
}}

ê·œì¹™:
1. victim_profileì€ ìš”ì•½ì—ì„œ ëª…í™•íˆ ë“œëŸ¬ë‚œ ì •ë³´ë§Œ ì¶”ì¶œ
2. vulnerability_questionsëŠ” ìµœì†Œ 5ê°œ, ìµœëŒ€ 8ê°œ ìƒì„±
3. ì§ˆë¬¸ì€ êµ¬ì²´ì ì´ê³  ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì‘ì„±
4. ë³´ì´ìŠ¤í”¼ì‹± ë°©ì–´ê°€ ì•„ë‹Œ **ê³µê²© ê°•í™”** ê´€ì 
""".strip()
    
    try:
        response = llm.invoke(prompt).content.strip()
        
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            response = response.split("```")[1].split("```")[0]
        
        result = json.loads(response)
        
        print(f"\nğŸ“Š ë¶„ì„ ì™„ë£Œ:")
        print(f"   - í”¼í•´ì: {result['victim_profile']['age_group']} {result['victim_profile']['occupation']}")
        print(f"   - ì‹œë‚˜ë¦¬ì˜¤: {result['current_scenario']}")
        print(f"   - ì·¨ì•½ì  ì§ˆë¬¸: {len(result['vulnerability_questions'])}ê°œ")
        
        return result
    
    except Exception as e:
        print(f"âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return {
            "victim_profile": {"age_group": "ì•Œ ìˆ˜ ì—†ìŒ", "occupation": "ì•Œ ìˆ˜ ì—†ìŒ"},
            "current_scenario": "ì•Œ ìˆ˜ ì—†ìŒ",
            "victim_suspicion_points": [],
            "vulnerability_questions": [],
            "error": str(e)
        }


@tool("generate_search_queries_from_question")
def generate_search_queries_from_question(
    question: str,
    victim_profile: Dict[str, Any],
) -> List[str]:
    """
    ì·¨ì•½ì  ì§ˆë¬¸ì„ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ë³€í™˜í•œë‹¤.
    ë³´ì´ìŠ¤í”¼ì‹±ê³¼ ì§ì ‘ ì—°ê´€ë˜ì§€ ì•Šì€, ì‹¬ë¦¬í•™/ì‚¬íšŒí•™ ê´€ì ì˜ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•œë‹¤.
    
    ì…ë ¥:
    - question: "30ëŒ€ëŠ” ì–´ë–¤ ì ì´ ì·¨ì•½í• ê¹Œ?"
    - victim_profile: í”¼í•´ì í”„ë¡œí•„
    
    ì¶œë ¥:
    ["30ëŒ€ ì‹¬ë¦¬ì  íŠ¹ì„±", "30ëŒ€ ìŠ¤íŠ¸ë ˆìŠ¤ ìš”ì¸", "ë°€ë ˆë‹ˆì–¼ ì„¸ëŒ€ ì†Œë¹„ íŒ¨í„´"]
    """
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.5, timeout=20)
    
    prompt = f"""
ë„ˆëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ ì „ë¬¸ê°€ë‹¤.

ì§ˆë¬¸: "{question}"
í”¼í•´ì ì •ë³´: {json.dumps(victim_profile, ensure_ascii=False)}

ì´ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ 3-5ê°œë¥¼ ìƒì„±í•˜ë¼.

ì¤‘ìš”:
- "ë³´ì´ìŠ¤í”¼ì‹±", "ì‚¬ê¸°", "í”¼ì‹±" ë“±ì˜ ë‹¨ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆë¼
- ì‹¬ë¦¬í•™, ì‚¬íšŒí•™, ë§ˆì¼€íŒ…, ì†Œë¹„ì í–‰ë™ ê´€ì ì˜ ê²€ìƒ‰ì–´
- ì¼ë°˜ì ì¸ íŠ¹ì„±/ì·¨ì•½ì ì„ ì°¾ê¸° ìœ„í•œ ê²€ìƒ‰ì–´
- ê° ì¿¼ë¦¬ëŠ” 10ì ì´ë‚´ë¡œ ì§§ê²Œ

ì˜ˆì‹œ:
ì§ˆë¬¸: "30ëŒ€ëŠ” ì–´ë–¤ ì ì´ ì·¨ì•½í• ê¹Œ?"
â†’ ["30ëŒ€ ì‹¬ë¦¬ íŠ¹ì„±", "ë°€ë ˆë‹ˆì–¼ ì„¸ëŒ€ ê°€ì¹˜ê´€", "30ëŒ€ ì¬í…Œí¬ ê´€ì‹¬ì‚¬", "ì§ì¥ì¸ ìŠ¤íŠ¸ë ˆìŠ¤"]

ì§ˆë¬¸: "ì§ì¥ì¸ì€ ë¬´ì—‡ì— ì•½í• ê¹Œ?"
â†’ ["ì§ì¥ì¸ ê³ ë¯¼ê±°ë¦¬", "ì§ì¥ ë‚´ ìŠ¤íŠ¸ë ˆìŠ¤", "íšŒì‚¬ì› ê±±ì •", "ì—…ë¬´ ì••ë°•ê°"]

ì¶œë ¥ í˜•ì‹ (JSON ë°°ì—´ë§Œ):
["ì¿¼ë¦¬1", "ì¿¼ë¦¬2", "ì¿¼ë¦¬3", ...]
""".strip()
    
    try:
        response = llm.invoke(prompt).content.strip()
        
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            response = response.split("```")[1].split("```")[0]
        
        queries = json.loads(response)
        
        if not isinstance(queries, list):
            queries = [str(queries)]
        
        print(f"   ğŸ” ìƒì„±ëœ ê²€ìƒ‰ì–´: {', '.join(queries[:3])}...")
        
        return queries[:5]  # ìµœëŒ€ 5ê°œ
    
    except Exception as e:
        print(f"   âš ï¸ ê²€ìƒ‰ì–´ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        # Fallback
        age = victim_profile.get("age_group", "")
        occupation = victim_profile.get("occupation", "")
        return [f"{age} íŠ¹ì„±", f"{occupation} ì‹¬ë¦¬", "ìŠ¤íŠ¸ë ˆìŠ¤ ìš”ì¸"]


@tool("search_vulnerability_info")
def search_vulnerability_info(
    search_queries: List[str],
) -> List[Dict[str, Any]]:
    """
    ì·¨ì•½ì  ê´€ë ¨ ì •ë³´ë¥¼ ì›¹ì—ì„œ ê²€ìƒ‰í•œë‹¤.
    
    ì…ë ¥:
    - search_queries: ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
    
    ì¶œë ¥:
    [{"title": "...", "url": "...", "content": "...", "query": "..."}, ...]
    """
    tavily = TavilySearch(
        max_results=3,
        topic="general",
        include_answer=False,
        include_raw_content=False,
        search_depth="basic",
    )
    
    all_results = []
    
    print(f"\nğŸŒ ì›¹ ê²€ìƒ‰ ì‹œì‘ ({len(search_queries)}ê°œ ì¿¼ë¦¬)")
    
    for query in search_queries:
        try:
            raw_out = tavily.invoke({"query": query})
            
            # Normalize
            if isinstance(raw_out, dict):
                results = raw_out.get("results", [])
            elif isinstance(raw_out, list):
                results = raw_out
            else:
                results = []
            
            for r in results[:2]:  # ê° ì¿¼ë¦¬ë‹¹ ìµœëŒ€ 2ê°œ
                all_results.append({
                    "title": r.get("title", "")[:100],
                    "url": r.get("url", ""),
                    "content": r.get("content", "")[:600],
                    "query": query
                })
            
            print(f"   âœ“ '{query}': {len(results)}ê°œ")
            
        except Exception as e:
            print(f"   âœ— '{query}': {str(e)}")
    
    print(f"   âœ… ì´ {len(all_results)}ê°œ ê²°ê³¼ ìˆ˜ì§‘")
    
    return all_results


@tool("generate_attack_techniques")
def generate_attack_techniques(
    vulnerability_info: List[Dict[str, Any]],
    victim_profile: Dict[str, Any],
    current_scenario: str,
    victim_suspicion_points: List[str],
) -> List[Dict[str, Any]]:
    """
    ìˆ˜ì§‘ëœ ì·¨ì•½ì  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°•í™”ëœ ê³µê²© ìˆ˜ë²• 10ê°œë¥¼ ìƒì„±í•œë‹¤.
    
    ì¶œë ¥:
    [
        {
            "technique": "ìˆ˜ë²• ì´ë¦„",
            "description": "ìˆ˜ë²• ì„¤ëª…",
            "application": "ì‹œë‚˜ë¦¬ì˜¤ ì ìš© ë°©ë²•",
            "expected_effect": "ì˜ˆìƒ íš¨ê³¼",
            "scenario_fit_score": 0.85  (0-1)
        },
        ...
    ]
    """
    llm = ChatOpenAI(model="gpt-4o", temperature=0.7, timeout=40)
    
    # ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬
    search_summary = []
    for i, item in enumerate(vulnerability_info[:15], 1):
        search_summary.append(
            f"{i}. [{item['query']}] {item['title']}\n{item['content']}\n"
        )
    
    prompt = f"""
ë„ˆëŠ” ë³´ì´ìŠ¤í”¼ì‹± ì‹œë‚˜ë¦¬ì˜¤ ì „ë¬¸ê°€ë‹¤...

ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ê³µê²©ì„ ê°•í™”í•  ìˆ˜ ìˆëŠ” ìˆ˜ë²• 10ê°œ**ë¥¼ ìƒì„±í•˜ë¼.

[í”¼í•´ì ì •ë³´]
{json.dumps(victim_profile, ensure_ascii=False, indent=2)}

[í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤]
{current_scenario}

[í”¼í•´ìê°€ ì˜ì‹¬í•œ í¬ì¸íŠ¸]
{json.dumps(victim_suspicion_points, ensure_ascii=False)}

[ì·¨ì•½ì  ì •ë³´ (ì›¹ ê²€ìƒ‰ ê²°ê³¼)]
{chr(10).join(search_summary)}

ì¶œë ¥ í˜•ì‹ (JSONë§Œ):
{{
  "techniques": [
    {{
      "technique": "ìˆ˜ë²• ì´ë¦„ (ê°„ê²°í•˜ê²Œ)",
      "description": "ìˆ˜ë²• ì„¤ëª… (2-3ë¬¸ì¥)",
      "application": "'{current_scenario}' ì‹œë‚˜ë¦¬ì˜¤ì— ì–´ë–»ê²Œ ì ìš©í• ì§€ êµ¬ì²´ì ìœ¼ë¡œ",
      "expected_effect": "í”¼í•´ìì—ê²Œ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì‹¬ë¦¬ì  íš¨ê³¼",
      "scenario_fit_score": 0.0~1.0 (í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ì— ì–¼ë§ˆë‚˜ ì í•©í•œì§€)
    }},
    ... (ì´ 10ê°œ)
  ]
}}

ê·œì¹™:
1. ì •í™•íˆ 10ê°œì˜ ìˆ˜ë²• ìƒì„±
2. ì›¹ ê²€ìƒ‰ì—ì„œ ë°œê²¬í•œ ì·¨ì•½ì ì„ **ë°˜ë“œì‹œ í™œìš©**
3. scenario_fit_scoreëŠ” ëƒ‰ì •í•˜ê²Œ í‰ê°€ (ë¬´ë¦¬í•˜ê²Œ ë†’ì´ì§€ ë§ˆë¼)
4. í”¼í•´ìê°€ ì˜ì‹¬í•œ í¬ì¸íŠ¸ë¥¼ ë³´ì™„í•˜ëŠ” ë°©í–¥
5. ìœ¤ë¦¬ì  ê²½ê³„ë¥¼ ë„˜ì§€ ì•Šë˜, ì‹¤ì „ ì ìš© ê°€ëŠ¥í•œ ìˆ˜ë²•
""".strip()
    
    try:
        print("\nğŸ§  LLMìœ¼ë¡œ ìˆ˜ë²• ìƒì„± ì¤‘...")
        response = llm.invoke(prompt).content.strip()
        
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            response = response.split("```")[1].split("```")[0]
        
        result = json.loads(response)
        techniques = result.get("techniques", [])
        
        print(f"   âœ… {len(techniques)}ê°œ ìˆ˜ë²• ìƒì„± ì™„ë£Œ")
        
        # ì ìˆ˜ë³„ ì •ë ¬
        techniques.sort(key=lambda x: x.get("scenario_fit_score", 0), reverse=True)
        
        return techniques
    
    except Exception as e:
        print(f"   âš ï¸ ìˆ˜ë²• ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return []


@tool("filter_and_select_techniques")
def filter_and_select_techniques(
    techniques: List[Dict[str, Any]],
    min_score: float = 0.6,
    target_count: int = 3,
) -> Dict[str, Any]:
    """
    ìƒì„±ëœ ìˆ˜ë²• ì¤‘ ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•œ ê²ƒë§Œ ì„ íƒí•œë‹¤.
    
    ì…ë ¥:
    - techniques: ìƒì„±ëœ ìˆ˜ë²• ë¦¬ìŠ¤íŠ¸
    - min_score: ìµœì†Œ ì í•©ë„ ì ìˆ˜ (ê¸°ë³¸ 0.6)
    - target_count: ëª©í‘œ ê°œìˆ˜ (ê¸°ë³¸ 3)
    
    ì¶œë ¥:
    {
        "selected": [...],  # ì„ íƒëœ ìˆ˜ë²•
        "count": 3,
        "need_more": false  # ì¶”ê°€ ìƒì„± í•„ìš” ì—¬ë¶€
    }
    """
    # ì ìˆ˜ í•„í„°ë§
    filtered = [
        t for t in techniques
        if t.get("scenario_fit_score", 0) >= min_score
    ]
    
    selected = filtered[:target_count * 2]  # ì—¬ìœ ìˆê²Œ ì„ íƒ
    
    need_more = len(selected) < target_count
    
    print(f"\nğŸ“‹ ìˆ˜ë²• í•„í„°ë§:")
    print(f"   - ì „ì²´: {len(techniques)}ê°œ")
    print(f"   - ì í•© (>={min_score}): {len(filtered)}ê°œ")
    print(f"   - ì„ íƒ: {len(selected)}ê°œ")
    print(f"   - ì¶”ê°€ í•„ìš”: {'ì˜ˆ' if need_more else 'ì•„ë‹ˆì˜¤'}")
    
    return {
        "selected": selected,
        "count": len(selected),
        "need_more": need_more
    }


@tool("create_attack_enhancement_report")
def create_attack_enhancement_report(
    conversation_summary: str,
    victim_profile: Dict[str, Any],
    current_scenario: str,
    selected_techniques: List[Dict[str, Any]],
    analysis_data: Dict[str, Any],
) -> Dict[str, Any]:
    """
    ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•œë‹¤.
    
    ì¶œë ¥:
    {
        "report": {
            "summary": "...",
            "victim_profile": {...},
            "enhanced_techniques": [...],
            "implementation_guide": "...",
            "expected_outcomes": [...]
        },
        "metadata": {...}
    }
    """
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, timeout=30)
    
    prompt = f"""
ë„ˆëŠ” ë³´ì´ìŠ¤í”¼ì‹± ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ë‹¤.

[ëŒ€í™” ìš”ì•½]
{conversation_summary}

[í”¼í•´ì í”„ë¡œí•„]
{json.dumps(victim_profile, ensure_ascii=False, indent=2)}

[í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤]
{current_scenario}

[ì„ íƒëœ ê°•í™” ìˆ˜ë²• {len(selected_techniques)}ê°œ]
{json.dumps(selected_techniques, ensure_ascii=False, indent=2)}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë‹¤ìŒ ëŒ€í™” ìƒì„±ì— í™œìš©í•  ìˆ˜ ìˆëŠ”** ì‹¤ì „ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ë¼.

ì¶œë ¥ í˜•ì‹ (JSON):
{{
  "summary": "ì´ë²ˆ ë¶„ì„ì˜ í•µì‹¬ ìš”ì•½ (3-4ë¬¸ì¥)",
  "victim_profile": {{
    "age_group": "...",
    "occupation": "...",
    "key_vulnerabilities": ["ì·¨ì•½ì 1", "ì·¨ì•½ì 2", ...]
  }},
  "enhanced_techniques": [
    {{
      "technique": "ìˆ˜ë²• ì´ë¦„",
      "why_effective": "ì™œ ì´ í”¼í•´ìì—ê²Œ íš¨ê³¼ì ì¸ì§€",
      "how_to_apply": "êµ¬ì²´ì  ì ìš© ë°©ë²• (ëŒ€ì‚¬ ì˜ˆì‹œ í¬í•¨)",
      "caution": "ì£¼ì˜ì‚¬í•­"
    }},
    ... (ì„ íƒëœ ìˆ˜ë²• ëª¨ë‘)
  ],
  "implementation_guide": "ì „ì²´ì ì¸ ì ìš© ê°€ì´ë“œ (ì‹œê°„ëŒ€, ìˆœì„œ, í†¤ ë“±)",
  "expected_outcomes": [
    "ì˜ˆìƒ ê²°ê³¼ 1",
    "ì˜ˆìƒ ê²°ê³¼ 2",
    ...
  ]
}}
""".strip()
    
    try:
        print("\nğŸ“ ìµœì¢… ë¦¬í¬íŠ¸ ì‘ì„± ì¤‘...")
        response = llm.invoke(prompt).content.strip()
        
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            response = response.split("```")[1].split("```")[0]
        
        report = json.loads(response)
        
        now = datetime.now(timezone.utc).isoformat()
        
        result = {
            "report": report,
            "metadata": {
                "created_at": now,
                "victim_profile": victim_profile,
                "techniques_analyzed": len(analysis_data.get("vulnerability_questions", [])),
                "techniques_generated": 10,
                "techniques_selected": len(selected_techniques),
                "scenario": current_scenario
            }
        }
        
        print("   âœ… ë¦¬í¬íŠ¸ ì‘ì„± ì™„ë£Œ")
        
        return result
    
    except Exception as e:
        print(f"   âš ï¸ ë¦¬í¬íŠ¸ ì‘ì„± ì‹¤íŒ¨: {str(e)}")
        return {
            "report": {},
            "metadata": {},
            "error": str(e)
        }