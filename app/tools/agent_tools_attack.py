# app/tools/agent_tools_attack.py (ìƒˆ íŒŒì¼)
from __future__ import annotations

import requests
from bs4 import BeautifulSoup
import time
import re

import json
from typing import List, Dict, Any, Optional
from datetime import datetime, timezone

from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch


@tool("analyze_conversation_summary")
def analyze_conversation_summary(
    conversation_summary: str,
) -> Dict[str, Any]:
    """
    ëŒ€í™” ìš”ì•½ì„ ë¶„ì„í•˜ì—¬ í”¼í•´ì í”„ë¡œí•„ê³¼ ì·¨ì•½ì  ì§ˆë¬¸ì„ ìƒì„±í•œë‹¤.
    
    ì…ë ¥:
    - conversation_summary: ëŒ€í™” ìš”ì•½ í…ìŠ¤íŠ¸
    
    ì¶œë ¥:
    {
        "victim_profile": {
            "age_group": "30ëŒ€",
            "occupation": "ì§ì¥ì¸",
            "gender": "ë‚¨ì„±",
            "characteristics": [...]
        },
        "current_scenario": "ê²€ê²½ ì‚¬ì¹­",
        "victim_suspicion_points": [...],
        "vulnerability_questions": [
            "30ëŒ€ëŠ” ì–´ë–¤ ì ì´ ì·¨ì•½í• ê¹Œ?",
            "ì§ì¥ì¸ì€ ë¬´ì—‡ì— ì•½í• ê¹Œ?",
            ...
        ]
    }
    """
    llm = ChatOpenAI(model="gpt-4o", temperature=0.3, timeout=30)
    
    prompt = f"""
ë„ˆëŠ” ë³´ì´ìŠ¤í”¼ì‹± ëŒ€í™”ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ë‹¤.
ì•„ë˜ ëŒ€í™” ìš”ì•½ì„ ì½ê³ , ê³µê²©ì ê´€ì ì—ì„œ í”¼í•´ìì˜ ì·¨ì•½ì ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ë¼.

[ëŒ€í™” ìš”ì•½]
{conversation_summary}

ì¶œë ¥ í˜•ì‹ (JSONë§Œ):
{{
  "victim_profile": {{
    "age_group": "ì—°ë ¹ëŒ€ (ì˜ˆ: 20ëŒ€, 30ëŒ€, 60ëŒ€ ì´ìƒ)",
    "occupation": "ì§ì—… (ì˜ˆ: ì§ì¥ì¸, ëŒ€í•™ìƒ, ì£¼ë¶€, í‡´ì§ì)",
    "gender": "ì„±ë³„ (ë‚¨ì„±/ì—¬ì„±/ì•Œ ìˆ˜ ì—†ìŒ)",
    "characteristics": ["íŠ¹ì§•1", "íŠ¹ì§•2", "íŠ¹ì§•3"]
  }},
  "current_scenario": "í˜„ì¬ ì‚¬ìš©ëœ ì‹œë‚˜ë¦¬ì˜¤ (ì˜ˆ: ê²€ê²½ ì‚¬ì¹­, ê°€ì¡± ì‚¬ì¹­, ëŒ€ì¶œ ì‚¬ê¸°)",
  "victim_suspicion_points": [
    "í”¼í•´ìê°€ ì˜ì‹¬í•œ í¬ì¸íŠ¸ 1",
    "í”¼í•´ìê°€ ì˜ì‹¬í•œ í¬ì¸íŠ¸ 2",
    ...
  ],
  "vulnerability_questions": [
    "ì´ ì—°ë ¹ëŒ€ëŠ” ì–´ë–¤ ì ì´ ì·¨ì•½í• ê¹Œ?",
    "ì´ ì§ì—…êµ°ì€ ë¬´ì—‡ì— ì•½í• ê¹Œ?",
    "ì–´ë–¤ ë§íˆ¬/í‘œí˜„ì´ íš¨ê³¼ì ì¼ê¹Œ?",
    "ì–´ë–¤ ì‹¬ë¦¬ì  ì••ë°•ì´ í†µí• ê¹Œ?",
    ...
  ]
}}

ê·œì¹™:
1. victim_profileì€ ìš”ì•½ì—ì„œ ëª…í™•íˆ ë“œëŸ¬ë‚œ ì •ë³´ë§Œ ì¶”ì¶œ
2. vulnerability_questionsëŠ” ìµœì†Œ 5ê°œ, ìµœëŒ€ 8ê°œ ìƒì„±
3. ì§ˆë¬¸ì€ êµ¬ì²´ì ì´ê³  ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì‘ì„±
4. ë³´ì´ìŠ¤í”¼ì‹± ë°©ì–´ê°€ ì•„ë‹Œ **ê³µê²© ê°•í™”** ê´€ì 
""".strip()
    
    try:
        response = llm.invoke(prompt).content.strip()
        
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            response = response.split("```")[1].split("```")[0]
        
        result = json.loads(response)
        
        print(f"\nğŸ“Š ë¶„ì„ ì™„ë£Œ:")
        print(f"   - í”¼í•´ì: {result['victim_profile']['age_group']} {result['victim_profile']['occupation']}")
        print(f"   - ì‹œë‚˜ë¦¬ì˜¤: {result['current_scenario']}")
        print(f"   - ì·¨ì•½ì  ì§ˆë¬¸: {len(result['vulnerability_questions'])}ê°œ")
        
        return result
    
    except Exception as e:
        print(f"âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return {
            "victim_profile": {"age_group": "ì•Œ ìˆ˜ ì—†ìŒ", "occupation": "ì•Œ ìˆ˜ ì—†ìŒ"},
            "current_scenario": "ì•Œ ìˆ˜ ì—†ìŒ",
            "victim_suspicion_points": [],
            "vulnerability_questions": [],
            "error": str(e)
        }


@tool("generate_search_queries_from_question")
def generate_search_queries_from_question(
    question: str,
    victim_profile: Dict[str, Any],
) -> List[str]:
    """
    ì·¨ì•½ì  ì§ˆë¬¸ì„ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ë³€í™˜í•œë‹¤.
    ë³´ì´ìŠ¤í”¼ì‹±ê³¼ ì§ì ‘ ì—°ê´€ë˜ì§€ ì•Šì€, ì‹¬ë¦¬í•™/ì‚¬íšŒí•™ ê´€ì ì˜ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•œë‹¤.
    
    ì…ë ¥:
    - question: "30ëŒ€ëŠ” ì–´ë–¤ ì ì´ ì·¨ì•½í• ê¹Œ?"
    - victim_profile: í”¼í•´ì í”„ë¡œí•„
    
    ì¶œë ¥:
    ["30ëŒ€ ì‹¬ë¦¬ì  íŠ¹ì„±", "30ëŒ€ ìŠ¤íŠ¸ë ˆìŠ¤ ìš”ì¸", "ë°€ë ˆë‹ˆì–¼ ì„¸ëŒ€ ì†Œë¹„ íŒ¨í„´"]
    """
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.5, timeout=20)
    
    prompt = f"""
ë„ˆëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ ì „ë¬¸ê°€ë‹¤.

ì§ˆë¬¸: "{question}"
í”¼í•´ì ì •ë³´: {json.dumps(victim_profile, ensure_ascii=False)}

ì´ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ 3-5ê°œë¥¼ ìƒì„±í•˜ë¼.

ì¤‘ìš”:
- "ë³´ì´ìŠ¤í”¼ì‹±", "ì‚¬ê¸°", "í”¼ì‹±" ë“±ì˜ ë‹¨ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆë¼
- ì‹¬ë¦¬í•™, ì‚¬íšŒí•™, ë§ˆì¼€íŒ…, ì†Œë¹„ì í–‰ë™ ê´€ì ì˜ ê²€ìƒ‰ì–´
- ì¼ë°˜ì ì¸ íŠ¹ì„±/ì·¨ì•½ì ì„ ì°¾ê¸° ìœ„í•œ ê²€ìƒ‰ì–´
- ê° ì¿¼ë¦¬ëŠ” 10ì ì´ë‚´ë¡œ ì§§ê²Œ

ì˜ˆì‹œ:
ì§ˆë¬¸: "30ëŒ€ëŠ” ì–´ë–¤ ì ì´ ì·¨ì•½í• ê¹Œ?"
â†’ ["30ëŒ€ ì‹¬ë¦¬ íŠ¹ì„±", "ë°€ë ˆë‹ˆì–¼ ì„¸ëŒ€ ê°€ì¹˜ê´€", "30ëŒ€ ì¬í…Œí¬ ê´€ì‹¬ì‚¬", "ì§ì¥ì¸ ìŠ¤íŠ¸ë ˆìŠ¤"]

ì§ˆë¬¸: "ì§ì¥ì¸ì€ ë¬´ì—‡ì— ì•½í• ê¹Œ?"
â†’ ["ì§ì¥ì¸ ê³ ë¯¼ê±°ë¦¬", "ì§ì¥ ë‚´ ìŠ¤íŠ¸ë ˆìŠ¤", "íšŒì‚¬ì› ê±±ì •", "ì—…ë¬´ ì••ë°•ê°"]

ì¶œë ¥ í˜•ì‹ (JSON ë°°ì—´ë§Œ):
["ì¿¼ë¦¬1", "ì¿¼ë¦¬2", "ì¿¼ë¦¬3", ...]
""".strip()
    
    try:
        response = llm.invoke(prompt).content.strip()
        
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            response = response.split("```")[1].split("```")[0]
        
        queries = json.loads(response)
        
        if not isinstance(queries, list):
            queries = [str(queries)]
        
        print(f"   ğŸ” ìƒì„±ëœ ê²€ìƒ‰ì–´: {', '.join(queries[:3])}...")
        
        return queries[:5]  # ìµœëŒ€ 5ê°œ
    
    except Exception as e:
        print(f"   âš ï¸ ê²€ìƒ‰ì–´ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        # Fallback
        age = victim_profile.get("age_group", "")
        occupation = victim_profile.get("occupation", "")
        return [f"{age} íŠ¹ì„±", f"{occupation} ì‹¬ë¦¬", "ìŠ¤íŠ¸ë ˆìŠ¤ ìš”ì¸"]


@tool("search_vulnerability_info")
def search_vulnerability_info(
    search_queries: List[str],
    extract_full_content: bool = True,
) -> List[Dict[str, Any]]:
    """
    ì·¨ì•½ì  ê´€ë ¨ ì •ë³´ë¥¼ ì›¹ì—ì„œ ê²€ìƒ‰í•˜ê³  ë³¸ë¬¸ê¹Œì§€ í¬ë¡¤ë§í•œë‹¤.
    
    ì…ë ¥:
    - search_queries: ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
    - extract_full_content: Trueë©´ ë³¸ë¬¸ í¬ë¡¤ë§ (ê¸°ë³¸ True)
    
    ì¶œë ¥:
    [{"title": "...", "url": "...", "content": "...(ì „ì²´ ë³¸ë¬¸)", "query": "..."}, ...]
    """
    from langchain_tavily import TavilySearch
    import requests
    from bs4 import BeautifulSoup
    import time
    
    # ì¤‘ë³µ ì œê±°
    unique_queries = list(dict.fromkeys(search_queries))  # ìˆœì„œ ìœ ì§€í•˜ë©´ì„œ ì¤‘ë³µ ì œê±°
    
    print(f"\nğŸŒ ì›¹ ê²€ìƒ‰ + ë³¸ë¬¸ í¬ë¡¤ë§ ({len(unique_queries)}ê°œ ê³ ìœ  ì¿¼ë¦¬)")
    
    tavily = TavilySearch(
        max_results=2,  # ê° ì¿¼ë¦¬ë‹¹ 2ê°œë§Œ
        topic="general",
        include_answer=False,
        include_raw_content=False,
        search_depth="basic",
    )
    
    all_urls = []
    seen_urls = set()  # URL ì¤‘ë³µ ë°©ì§€
    
    # 1ë‹¨ê³„: URL ìˆ˜ì§‘
    for query in unique_queries:
        try:
            raw_out = tavily.invoke({"query": query})
            
            if isinstance(raw_out, dict):
                results = raw_out.get("results", [])
            elif isinstance(raw_out, list):
                results = raw_out
            else:
                results = []
            
            for r in results[:2]:
                url = r.get("url", "").strip()
                
                # ì¤‘ë³µ URL ìŠ¤í‚µ
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    all_urls.append({
                        "url": url,
                        "title": r.get("title", "")[:100],
                        "snippet": r.get("content", "")[:300],
                        "query": query
                    })
            
            print(f"   âœ“ '{query}': {len(results)}ê°œ")
            
        except Exception as e:
            print(f"   âœ— '{query}': {str(e)}")
    
    if not all_urls:
        print("   âš ï¸  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return []
    
    print(f"   â†’ ì´ {len(all_urls)}ê°œ ê³ ìœ  URL ìˆ˜ì§‘")
    
    all_results = []
    
    # 2ë‹¨ê³„: ë³¸ë¬¸ í¬ë¡¤ë§
    if extract_full_content:
        print(f"\nğŸ“„ ë³¸ë¬¸ í¬ë¡¤ë§ ì‹œì‘ ({len(all_urls)}ê°œ URL)")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        success_count = 0
        
        for i, item in enumerate(all_urls[:15], 1):  # ìµœëŒ€ 15ê°œ
            try:
                time.sleep(0.5)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
                
                response = requests.get(item["url"], headers=headers, timeout=10)
                response.raise_for_status()
                
                # ì¸ì½”ë”© ì²˜ë¦¬
                if response.encoding is None or response.encoding == 'ISO-8859-1':
                    response.encoding = response.apparent_encoding or 'utf-8'
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ë³¸ë¬¸ ì¶”ì¶œ (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
                content_elem = None
                
                # íŒ¨í„´ 1: ì‹œë§¨í‹± íƒœê·¸
                content_elem = soup.select_one('article')
                
                # íŒ¨í„´ 2: ì¼ë°˜ì ì¸ í´ë˜ìŠ¤ëª…
                if not content_elem:
                    for selector in [
                        'div.content', 'div.post-content', 'div.article-body',
                        'div#content', 'main', 'div.entry-content',
                        'div.post_content', 'div.article_body'
                    ]:
                        content_elem = soup.select_one(selector)
                        if content_elem:
                            break
                
                # íŒ¨í„´ 3: bodyì—ì„œ ë¶ˆí•„ìš” ìš”ì†Œ ì œê±°
                if not content_elem:
                    content_elem = soup.select_one('body')
                
                if content_elem:
                    # ë¶ˆí•„ìš” ìš”ì†Œ ì œê±°
                    for tag in content_elem(['script', 'style', 'nav', 'header', 
                                            'footer', 'aside', 'iframe', 'noscript']):
                        tag.decompose()
                    
                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    content = content_elem.get_text(separator='\n', strip=True)
                    
                    # ì •ì œ
                    import re
                    content = re.sub(r'\n\s*\n', '\n\n', content)
                    content = re.sub(r' +', ' ', content)
                    
                    # ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
                    if len(content) < 100:
                        print(f"   [{i}/{len(all_urls)}] âœ— {item['title'][:30]}... (ë³¸ë¬¸ ë„ˆë¬´ ì§§ìŒ: {len(content)}ì)")
                        all_results.append({
                            "title": item["title"],
                            "url": item["url"],
                            "content": item["snippet"],
                            "query": item["query"],
                            "content_type": "snippet"
                        })
                        continue
                    
                    all_results.append({
                        "title": item["title"],
                        "url": item["url"],
                        "content": content[:3000],  # ìµœëŒ€ 3000ì
                        "query": item["query"],
                        "content_type": "full_crawled"
                    })
                    
                    success_count += 1
                    print(f"   [{i}/{len(all_urls)}] âœ“ {item['title'][:30]}... ({len(content)}ì)")
                else:
                    print(f"   [{i}/{len(all_urls)}] âœ— {item['title'][:30]}... (ë³¸ë¬¸ ëª»ì°¾ìŒ)")
                    all_results.append({
                        "title": item["title"],
                        "url": item["url"],
                        "content": item["snippet"],
                        "query": item["query"],
                        "content_type": "snippet"
                    })
            
            except requests.Timeout:
                print(f"   [{i}/{len(all_urls)}] âœ— {item['url'][:40]}... (íƒ€ì„ì•„ì›ƒ)")
                all_results.append({
                    "title": item["title"],
                    "url": item["url"],
                    "content": item["snippet"],
                    "query": item["query"],
                    "content_type": "snippet"
                })
            
            except Exception as e:
                print(f"   [{i}/{len(all_urls)}] âœ— ì˜¤ë¥˜: {str(e)[:50]}")
                all_results.append({
                    "title": item["title"],
                    "url": item["url"],
                    "content": item["snippet"],
                    "query": item["query"],
                    "content_type": "snippet"
                })
        
        print(f"   âœ… ë³¸ë¬¸ í¬ë¡¤ë§ ì™„ë£Œ: {success_count}/{len(all_urls)}ê°œ ì„±ê³µ")
    else:
        # ìŠ¤ë‹ˆí«ë§Œ
        for item in all_urls:
            all_results.append({
                "title": item["title"],
                "url": item["url"],
                "content": item["snippet"],
                "query": item["query"],
                "content_type": "snippet"
            })
        print(f"   â„¹ï¸  ìŠ¤ë‹ˆí«ë§Œ ì‚¬ìš© ({len(all_results)}ê°œ)")
    
    return all_results[:15]

@tool("search_and_extract_vulnerability_info")
def search_and_extract_vulnerability_info(
    search_queries: List[str],
    max_articles_per_query: int = 2,
) -> List[Dict[str, Any]]:
    """
    ì·¨ì•½ì  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ë³¸ë¬¸ê¹Œì§€ í¬ë¡¤ë§í•œë‹¤.
    
    ì…ë ¥:
    - search_queries: ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
    - max_articles_per_query: ê° ì¿¼ë¦¬ë‹¹ ìµœëŒ€ ê¸€ ìˆ˜
    
    ì¶œë ¥:
    [{"title": "...", "url": "...", "content": "...(ì „ì²´ ë³¸ë¬¸)", "query": "..."}, ...]
    """
    from langchain_tavily import TavilySearch
    import requests
    from bs4 import BeautifulSoup
    import time
    
    tavily = TavilySearch(
        max_results=max_articles_per_query + 1,
        topic="general",
        include_raw_content=False,
        search_depth="basic",
    )
    
    all_results = []
    
    print(f"\nğŸŒ ì›¹ ê²€ìƒ‰ + ë³¸ë¬¸ ì¶”ì¶œ ({len(search_queries)}ê°œ ì¿¼ë¦¬)")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    for query in search_queries:
        try:
            # 1) ê²€ìƒ‰ìœ¼ë¡œ URL ìˆ˜ì§‘
            raw_out = tavily.invoke({"query": query})
            
            if isinstance(raw_out, dict):
                results = raw_out.get("results", [])
            elif isinstance(raw_out, list):
                results = raw_out
            else:
                results = []
            
            urls_to_crawl = []
            for r in results[:max_articles_per_query]:
                url = r.get("url", "").strip()
                title = r.get("title", "")
                if url:
                    urls_to_crawl.append({"url": url, "title": title})
            
            print(f"   ğŸ” '{query}': {len(urls_to_crawl)}ê°œ URL ë°œê²¬")
            
            # 2) ê° URLì˜ ë³¸ë¬¸ í¬ë¡¤ë§
            for item in urls_to_crawl:
                try:
                    time.sleep(1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
                    
                    response = requests.get(item["url"], headers=headers, timeout=10)
                    response.raise_for_status()
                    response.encoding = response.apparent_encoding or 'utf-8'
                    
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # ë³¸ë¬¸ ì¶”ì¶œ
                    content_elem = (
                        soup.select_one('article') or
                        soup.select_one('div.content') or
                        soup.select_one('div.post-content') or
                        soup.select_one('main') or
                        soup.select_one('div#content')
                    )
                    
                    if content_elem:
                        # script/style ì œê±°
                        for tag in content_elem(['script', 'style', 'nav', 'header', 'footer', 'aside']):
                            tag.decompose()
                        
                        content = content_elem.get_text(separator='\n', strip=True)
                        
                        # ì •ì œ
                        import re
                        content = re.sub(r'\n\s*\n', '\n\n', content)
                        content = re.sub(r' +', ' ', content)
                        
                        all_results.append({
                            "title": item["title"],
                            "url": item["url"],
                            "content": content[:3000],  # ìµœëŒ€ 3000ì
                            "query": query,
                            "content_type": "full_crawled"
                        })
                        
                        print(f"      âœ“ {item['title'][:40]}... ({len(content)}ì)")
                    else:
                        print(f"      âœ— {item['title'][:40]}... (ë³¸ë¬¸ ëª»ì°¾ìŒ)")
                
                except Exception as e:
                    print(f"      âœ— {item['url'][:40]}... ì˜¤ë¥˜: {str(e)}")
                    continue
            
        except Exception as e:
            print(f"   âœ— '{query}': {str(e)}")
    
    print(f"\n   âœ… ì´ {len(all_results)}ê°œ ë³¸ë¬¸ ì¶”ì¶œ ì™„ë£Œ")
    
    return all_results


@tool("generate_attack_techniques")
def generate_attack_techniques(
    vulnerability_info: List[Dict[str, Any]],
    victim_profile: Dict[str, Any],
    current_scenario: str,
    victim_suspicion_points: List[str],
) -> List[Dict[str, Any]]:
    """ìˆ˜ì§‘ëœ ì·¨ì•½ì  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°•í™”ëœ ê³µê²© ìˆ˜ë²• 10ê°œë¥¼ ìƒì„±"""
    
    llm = ChatOpenAI(model="gpt-4o", temperature=0.7, timeout=60)
    
    # ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ê²½ê³ 
    if len(vulnerability_info) < 3:
        print(f"   âš ï¸  ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡±: {len(vulnerability_info)}ê°œ")
    
    # ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬
    search_summary = []
    for i, item in enumerate(vulnerability_info[:15], 1):
        content_type = item.get('content_type', 'unknown')
        content_len = len(item.get('content', ''))
        
        search_summary.append(
            f"{i}. [{item['query']}] ({content_type}, {content_len}ì)\n"
            f"   ì œëª©: {item['title']}\n"
            f"   ë‚´ìš©: {item['content'][:500]}\n"
        )
    
    prompt = f"""
ë„ˆëŠ” ë³´ì´ìŠ¤í”¼ì‹± ì‹œë‚˜ë¦¬ì˜¤ ì „ë¬¸ê°€ë‹¤.

[í”¼í•´ì ì •ë³´]
{json.dumps(victim_profile, ensure_ascii=False, indent=2)}

[í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤]
{current_scenario}

[í”¼í•´ìê°€ ì˜ì‹¬í•œ í¬ì¸íŠ¸]
{json.dumps(victim_suspicion_points, ensure_ascii=False)}

[ì·¨ì•½ì  ì •ë³´ ({len(vulnerability_info)}ê°œ)]
{chr(10).join(search_summary)}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ê³µê²©ì„ ê°•í™”í•  ìˆ˜ ìˆëŠ” ìˆ˜ë²• 10ê°œ**ë¥¼ ìƒì„±í•˜ë¼.

ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSONë§Œ, ë§ˆí¬ë‹¤ìš´/ì£¼ì„ ê¸ˆì§€):
{{
  "techniques": [
    {{
      "technique": "ìˆ˜ë²• ì´ë¦„",
      "description": "ìˆ˜ë²• ì„¤ëª…",
      "application": "'{current_scenario}' ì‹œë‚˜ë¦¬ì˜¤ ì ìš© ë°©ë²•",
      "expected_effect": "ì˜ˆìƒ ì‹¬ë¦¬ì  íš¨ê³¼",
      "scenario_fit_score": 0.85
    }},
    ... (ì •í™•íˆ 10ê°œ)
  ]
}}

ê·œì¹™:
1. ì •í™•íˆ 10ê°œ ìƒì„±
2. scenario_fit_scoreëŠ” 0.0~1.0 (ëƒ‰ì •í•˜ê²Œ í‰ê°€)
3. ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ í™œìš©
4. JSONë§Œ ì¶œë ¥ (```json ì½”ë“œë¸”ë¡ ê¸ˆì§€)
""".strip()
    
    try:
        print("\nğŸ§  LLMìœ¼ë¡œ ìˆ˜ë²• ìƒì„± ì¤‘...")
        response = llm.invoke(prompt).content.strip()
        
        print(f"   ğŸ“ ì‘ë‹µ ê¸¸ì´: {len(response)}ì")
        print(f"   ğŸ“ ì‘ë‹µ ì‹œì‘: {response[:100]}...")
        
        # JSON ì¶”ì¶œ (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
        json_text = response
        
        if "```json" in response:
            json_text = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            json_text = response.split("```")[1].split("```")[0]
        
        json_text = json_text.strip()
        
        # JSON íŒŒì‹±
        result = json.loads(json_text)
        techniques = result.get("techniques", [])
        
        if not techniques:
            print("   âš ï¸  techniques ë°°ì—´ì´ ë¹„ì–´ìˆìŒ")
            return []
        
        print(f"   âœ… {len(techniques)}ê°œ ìˆ˜ë²• ìƒì„± ì™„ë£Œ")
        
        # ì ìˆ˜ë³„ ì •ë ¬
        techniques.sort(key=lambda x: x.get("scenario_fit_score", 0), reverse=True)
        
        return techniques
    
    except json.JSONDecodeError as e:
        print(f"   âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        print(f"   ğŸ“„ ì‘ë‹µ ì „ì²´:\n{response[:500]}...")
        return []
    
    except Exception as e:
        print(f"   âš ï¸ ìˆ˜ë²• ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return []


@tool("filter_and_select_techniques")
def filter_and_select_techniques(
    techniques: List[Dict[str, Any]],
    min_score: float = 0.6,
    target_count: int = 3,
) -> Dict[str, Any]:
    """
    ìƒì„±ëœ ìˆ˜ë²• ì¤‘ ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•œ ê²ƒë§Œ ì„ íƒí•œë‹¤.
    
    ì…ë ¥:
    - techniques: ìƒì„±ëœ ìˆ˜ë²• ë¦¬ìŠ¤íŠ¸
    - min_score: ìµœì†Œ ì í•©ë„ ì ìˆ˜ (ê¸°ë³¸ 0.6)
    - target_count: ëª©í‘œ ê°œìˆ˜ (ê¸°ë³¸ 3)
    
    ì¶œë ¥:
    {
        "selected": [...],  # ì„ íƒëœ ìˆ˜ë²•
        "count": 3,
        "need_more": false  # ì¶”ê°€ ìƒì„± í•„ìš” ì—¬ë¶€
    }
    """
    # ì ìˆ˜ í•„í„°ë§
    filtered = [
        t for t in techniques
        if t.get("scenario_fit_score", 0) >= min_score
    ]
    
    selected = filtered[:target_count * 2]  # ì—¬ìœ ìˆê²Œ ì„ íƒ
    
    need_more = len(selected) < target_count
    
    print(f"\nğŸ“‹ ìˆ˜ë²• í•„í„°ë§:")
    print(f"   - ì „ì²´: {len(techniques)}ê°œ")
    print(f"   - ì í•© (>={min_score}): {len(filtered)}ê°œ")
    print(f"   - ì„ íƒ: {len(selected)}ê°œ")
    print(f"   - ì¶”ê°€ í•„ìš”: {'ì˜ˆ' if need_more else 'ì•„ë‹ˆì˜¤'}")
    
    return {
        "selected": selected,
        "count": len(selected),
        "need_more": need_more
    }


@tool("create_attack_enhancement_report")
def create_attack_enhancement_report(
    conversation_summary: str,
    victim_profile: Dict[str, Any],
    current_scenario: str,
    selected_techniques: List[Dict[str, Any]],
    analysis_data: Dict[str, Any],
) -> Dict[str, Any]:
    """
    ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•œë‹¤.
    
    ì¶œë ¥:
    {
        "report": {
            "summary": "...",
            "victim_profile": {...},
            "enhanced_techniques": [...],
            "implementation_guide": "...",
            "expected_outcomes": [...]
        },
        "metadata": {...}
    }
    """
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, timeout=30)
    
    prompt = f"""
ë„ˆëŠ” ë³´ì´ìŠ¤í”¼ì‹± ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ë‹¤.

[ëŒ€í™” ìš”ì•½]
{conversation_summary}

[í”¼í•´ì í”„ë¡œí•„]
{json.dumps(victim_profile, ensure_ascii=False, indent=2)}

[í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤]
{current_scenario}

[ì„ íƒëœ ê°•í™” ìˆ˜ë²• {len(selected_techniques)}ê°œ]
{json.dumps(selected_techniques, ensure_ascii=False, indent=2)}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë‹¤ìŒ ëŒ€í™” ìƒì„±ì— í™œìš©í•  ìˆ˜ ìˆëŠ”** ì‹¤ì „ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ë¼.

ì¶œë ¥ í˜•ì‹ (JSON):
{{
  "summary": "ì´ë²ˆ ë¶„ì„ì˜ í•µì‹¬ ìš”ì•½ (3-4ë¬¸ì¥)",
  "victim_profile": {{
    "age_group": "...",
    "occupation": "...",
    "key_vulnerabilities": ["ì·¨ì•½ì 1", "ì·¨ì•½ì 2", ...]
  }},
  "enhanced_techniques": [
    {{
      "technique": "ìˆ˜ë²• ì´ë¦„",
      "why_effective": "ì™œ ì´ í”¼í•´ìì—ê²Œ íš¨ê³¼ì ì¸ì§€",
      "how_to_apply": "êµ¬ì²´ì  ì ìš© ë°©ë²• (ëŒ€ì‚¬ ì˜ˆì‹œ í¬í•¨)",
      "caution": "ì£¼ì˜ì‚¬í•­"
    }},
    ... (ì„ íƒëœ ìˆ˜ë²• ëª¨ë‘)
  ],
  "implementation_guide": "ì „ì²´ì ì¸ ì ìš© ê°€ì´ë“œ (ì‹œê°„ëŒ€, ìˆœì„œ, í†¤ ë“±)",
  "expected_outcomes": [
    "ì˜ˆìƒ ê²°ê³¼ 1",
    "ì˜ˆìƒ ê²°ê³¼ 2",
    ...
  ]
}}
""".strip()
    
    try:
        print("\nğŸ“ ìµœì¢… ë¦¬í¬íŠ¸ ì‘ì„± ì¤‘...")
        response = llm.invoke(prompt).content.strip()
        
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            response = response.split("```")[1].split("```")[0]
        
        report = json.loads(response)
        
        now = datetime.now(timezone.utc).isoformat()
        
        result = {
            "report": report,
            "metadata": {
                "created_at": now,
                "victim_profile": victim_profile,
                "techniques_analyzed": len(analysis_data.get("vulnerability_questions", [])),
                "techniques_generated": 10,
                "techniques_selected": len(selected_techniques),
                "scenario": current_scenario
            }
        }
        
        print("   âœ… ë¦¬í¬íŠ¸ ì‘ì„± ì™„ë£Œ")
        
        return result
    
    except Exception as e:
        print(f"   âš ï¸ ë¦¬í¬íŠ¸ ì‘ì„± ì‹¤íŒ¨: {str(e)}")
        return {
            "report": {},
            "metadata": {},
            "error": str(e)
        }